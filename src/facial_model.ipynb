{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers import LSTM, Input, Flatten, Concatenate, Embedding, Convolution1D,Dropout, Conv3D, Conv2D, Conv1D, Bidirectional, Reshape, MaxPooling1D, AveragePooling1D\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers.convolutional import Conv3D, ZeroPadding3D\n",
    "from keras.layers.convolutional import MaxPooling3D, AveragePooling3D\n",
    "from keras.layers import add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import argparse\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import regularizers, constraints, initializers, activations\n",
    "from keras.layers.recurrent import Recurrent\n",
    "from keras.engine import InputSpec\n",
    "from keras.callbacks import EarlyStopping,TensorBoard, ModelCheckpoint\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from keras_multi_head import MultiHeadAttention\n",
    "\n",
    "import pickle as plk\n",
    "\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "keras.backend.tensorflow_backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_unit = 512\n",
    "dropout_rate = 0.35\n",
    "lstm_cells = 128\n",
    "classes = 6\n",
    "batch = 16\n",
    "epochs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_facial_tra = plk.load(open('../data_clean/split/data_visual_tra', 'rb'))\n",
    "data_facial_pre_tra = plk.load(open('../data_clean/split/data_visual_pre_tra', 'rb'))\n",
    "\n",
    "data_facial_tes = plk.load(open('../data_clean/split/data_visual_tes', 'rb'))\n",
    "data_facial_pre_tes = plk.load(open('../data_clean/split/data_visual_pre_tes', 'rb'))\n",
    "\n",
    "data_emos_tra = plk.load(open('../data_clean/split/data_emos_tra_', 'rb'))\n",
    "\n",
    "data_emos_tes = plk.load(open('../data_clean/split/data_emos_tes', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "loop_n = {0:3,1:2,2:1,3:2,4:2,5:1}\n",
    "for (faces, faces_pre, emo) in zip(data_facial_tra, data_facial_pre_tra, data_emos_tra):\n",
    "    for _ in range(loop_n[emo]):\n",
    "        data.append([faces, faces_pre, emo])\n",
    "        \n",
    "np.random.shuffle(data)\n",
    "data_facial_tra, data_facial_pre_tra, data_emos_tra = [], [], []\n",
    "for (faces, faces_pre, emo) in data:\n",
    "    data_facial_tra.append(faces)\n",
    "    data_facial_pre_tra.append(faces_pre)\n",
    "    data_emos_tra.append(emo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 'float32'\n",
    "[data_facial_tra, data_facial_pre_tra, \n",
    " data_facial_tes, data_facial_pre_tes, \n",
    " data_emos_tra, data_emos_tes\n",
    "]   =    [np.reshape(np.asarray(data_facial_tra, data_type), (9348, 512, 1)), np.reshape(np.asarray(data_facial_pre_tra, data_type), (9348, 512, 1)), \n",
    "                                      np.reshape(data_facial_tes, (1623, 512, 1)), np.reshape(data_facial_pre_tes, (1623, 512, 1)),\n",
    "                                      to_categorical(data_emos_tra, 6), to_categorical(data_emos_tes, 6)\n",
    "                                      ]\n",
    "\n",
    "print('data_facial_tra:', np.shape(data_facial_tra))\n",
    "print('data_facial_tes:', np.shape(data_facial_tes))\n",
    "\n",
    "print('data_facial_pre_tra:', np.shape(data_facial_pre_tra))\n",
    "print('data_facial_pre_tes:', np.shape(data_facial_pre_tes))\n",
    "\n",
    "print('data_emos_tra:', np.shape(data_emos_tra))\n",
    "print('data_emos_tes:', np.shape(data_emos_tes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_faces = Input((512,1))\n",
    "faces = Input((512,1))\n",
    "\n",
    "Facial_processing = Sequential()\n",
    "Facial_processing.add(Conv1D(64, 3, strides=1))\n",
    "Facial_processing.add(EmoEncDec(lstm_cells,lstm_cells, name='EmoEncDec'))\n",
    "# Facial_processing.add(LSTM(lstm_cells, return_sequences=True, name='EmoEncDec_LSTM'))\n",
    "Facial_processing.add(MultiHeadAttention(head_num=8))\n",
    "# Facial_processing.add(Dropout(dropout_rate))\n",
    "# Facial_processing.add(Flatten())\n",
    "Facial_processing.add(Bidirectional(LSTM(lstm_cells, recurrent_dropout = 0.2)))\n",
    "\n",
    "\n",
    "pre_mocab_feature = Facial_processing(pre_faces)\n",
    "mocab_feature = Facial_processing(faces)\n",
    "\n",
    "\n",
    "merge = Concatenate(axis=-1)([pre_faces, faces])\n",
    "\n",
    "R = Flatten()(merge)\n",
    "R = Dense(64)(R)\n",
    "emo = Dense(classes, name='emo', activation='softmax')(R)\n",
    "\n",
    "\n",
    "model = Model(inputs=[pre_faces, faces],outputs=emo)\n",
    "Facial_processing.summary()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss={'emo':'categorical_crossentropy',\n",
    "#                         'gen':'categorical_crossentropy',\n",
    "                    },\n",
    "              loss_weights={'emo':1.,\n",
    "#                             'gen':1.,\n",
    "                            },\n",
    "              metrics=['acc'])\n",
    "file_path_root = './facial/'\n",
    "model_file = file_path_root+'facial_model.h5'\n",
    "callback_list = [\n",
    "                    TensorBoard(log_dir=file_path_root),\n",
    "                    EarlyStopping(\n",
    "                        monitor='val_acc',\n",
    "                        patience=500,\n",
    "                        verbose=1,\n",
    "                        mode='auto'\n",
    "                    ),\n",
    "                    ModelCheckpoint(\n",
    "                        filepath=model_file,\n",
    "                        monitor='val_acc',\n",
    "                        save_best_only='True',\n",
    "                        verbose=1,\n",
    "                        mode='auto',\n",
    "                        period=1\n",
    "                    )\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = model.fit([data_facial_pre_tra, data_facial_tra], \n",
    "          data_emos_tra,\n",
    "          batch_size=batch,\n",
    "          epochs=epochs,\n",
    "          callbacks=callback_list,      \n",
    "          validation_data=([data_facial_pre_tes, data_facial_tes], \n",
    "                           data_emos_tes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "model = load_model(model_file, custom_objects={'MultiHeadAttention':MultiHeadAttention, 'EmoEncDec': EmoEncDec})\n",
    "\n",
    "predicted_test_labels = model.predict([data_facial_pre_tes, data_facial_tes]).argmax(axis=1)\n",
    "numeric_test_labels = np.array(data_emos_tes).argmax(axis=1)\n",
    "\n",
    "report_filename = file_path_root+'Results.txt' \n",
    "\n",
    "with open(report_filename, 'w', encoding='utf-8') as f:\n",
    "    print(classification_report(numeric_test_labels, predicted_test_labels, target_names = ['hap', 'sad', 'neu', 'ang', 'exc', 'fru'], digits=4), file=f)\n",
    "print(classification_report(numeric_test_labels, predicted_test_labels, target_names = ['hap', 'sad', 'neu', 'ang', 'exc', 'fru'], digits=4))\n",
    "labels = ['hap', 'sad', 'neu', 'ang', 'exc', 'fru']\n",
    "print('   '+' '.join(labels))\n",
    "cm = confusion_matrix(y_true=numeric_test_labels.tolist(), y_pred=predicted_test_labels.tolist())\n",
    "print(cm)\n",
    "\n",
    "\n",
    "nor_cm = []\n",
    "for i in range(6):\n",
    "    row_sum = cm[i].sum()\n",
    "#     print(row_sum)\n",
    "    l_n = []\n",
    "    for j in range(6):\n",
    "        l_n.append(cm[i][j]/row_sum)\n",
    "    nor_cm.append(l_n)\n",
    "    \n",
    "df_cm = pd.DataFrame(nor_cm, index = [i for i in ['hap', 'sad', 'neu', 'ang', 'exc', 'fru']],\n",
    "                  columns = [i for i in ['hap', 'sad', 'neu', 'ang', 'exc', 'fru']])\n",
    "\n",
    "sn.heatmap(df_cm,  annot=True)\n",
    "plt.savefig(file_path_root+'cm.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
